{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_linear.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rkrissada/google_ml_training/blob/master/mnist_linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RkHid5JW8RF",
        "colab_type": "text"
      },
      "source": [
        "# MNIST Image Classification with TensorFlow\n",
        "\n",
        "This notebook demonstrates how to implement a simple linear image models on MNIST using Estimator.\n",
        "<hr/>\n",
        "This <a href=\"mnist_models.ipynb\">companion notebook</a> extends the basic harness of this notebook to a variety of models including DNN, CNN, dropout, pooling etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQS_riViW8RH",
        "colab_type": "code",
        "colab": {},
        "outputId": "52784990-5b94-4246-cacb-bba81838505f"
      },
      "source": [
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiAPwjQ5W8RM",
        "colab_type": "text"
      },
      "source": [
        "## Exploring the data\n",
        "\n",
        "Let's download MNIST data and examine the shape. We will need these numbers ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10ku9ynYW8RN",
        "colab_type": "code",
        "colab": {},
        "outputId": "397d653d-4036-4d37-8eff-63c75c3ae761"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "mnist = input_data.read_data_sets(\"mnist/data\", one_hot = True, reshape = False)\n",
        "print(mnist.train.images.shape)\n",
        "print(mnist.train.labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-2-09f4f2344a9e>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "(55000, 28, 28, 1)\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJt0MUoW8RQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 28\n",
        "WIDTH = 28\n",
        "NCLASSES = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYr1Oj2WW8RS",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b788e0c-5774-49f5-c2b9-8b9439ee1181"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "IMGNO = 200\n",
        "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
            "  (prop.get_family(), self.defaultFamily[fontext]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADr1JREFUeJzt3W+sVPWdx/E3XPABrRHRVNBqgA33mxpkXVMVw2ZDY5a4ioF6RYuit9mmNIY+0CXZGJ9o0tSg2y6L0VQtJWBsqSQXVsBGNJcH7MZA+ONqXd2vaVikd1FgBRUlBu6ffTDD7Mwwc2buzDkzw/1+Xk/u+Z3fnXO+Dn7umTO/c85v3MjICCIy9o1vdwEi0hoKu0gQCrtIEAq7SBAKu0gQE1q8P331L5K9cZVWNhV2M7sNWAN0AWvdfVUz2xOR7IxrdJzdzLqAD4G/BQaAvcBSd38/4WU6sotkr+KRvZlz9puAP7n7QXc/A/weWNTE9kQkQ82E/Srgz0Xtgfw6EelAzYS90kcFfUwX6VDNhH0AuLqo/W3gSHPliEhWmvk2fi8wy8xmAP8D/AC4L5WqRCR1DR/Z3X0Q+CmwA/gA2OTu/5lWYSKSroaH3hqkc3qR7KU+9CYiFxCFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kiFZP2SwV7Nu3L7H/o48+Kiz39PTQ19dX0n/33XdXfe348dn+PR8eHi4sj4yMMG5c6YNNm9n/8uXLE/sfeeSRxP7u7u6G9z0W6cguEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoRmcW2BrVu3JvY/+OCDif1ffvllYXlwcJAJE0ovj0j6Nywf905b8b6Hhobo6upq2f5rvW8vvPBCYXnixImcPXu2pD2GVXzTm7qoxswOAaeAIWDQ3b/bzPZEJDtpXEH3PXf/3xS2IyIZ0jm7SBBNnbOb2X8DJ8mdi7/g7i/WeEnIc3aRFkv/nB2Y5+5HzOxbwJtm9l/uvqvJbY45+oIuG/qCbnSa+hjv7kfyP48BW4Cb0ihKRNLXcNjN7BtmdvG5ZWAB8F5ahYlIuho+ZzezmeSO5pA7Hfidu/+8xstCnrPPmTMnsf/999+ve1v6GF9535UcP368sDxlyhROnDhR0h7D0j1nd/eDwF82XI6ItJSG3kSCUNhFglDYRYJQ2EWCUNhFgtCjpGXM2rZtW2G5t7f3vHY0OrKLBKGwiwShsIsEobCLBKGwiwShsIsEobCLBKFx9ha44447EvtHc4ur1G/nzp2F5d7e3vPa0ejILhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKExtlb4KGHHkrsP3LkyKi2d//995e0V69ePeqa6vXkk08m9me572bNnj07sR2NjuwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQTQ8ZXODQk7ZnLWvv/66at9XX32V+Nq1a9cm9q9fvz6x/8MPPywst3rK5lr3pD///POF5YkTJ3L27NmS9hjW2JTNZrYOWAgcc/fZ+XVTgFeA6cAh4B53P5lWpSKSvno+xq8Hbitb9yjQ7+6zgP58W0Q6WM2wu/su4ETZ6kXAhvzyBmBxynWJSMrqOmc3s+nA9qKP8Z+5++Si/pPufmkd+9M5u0j2Gjtnl86nL+gqC/wFXUWNDr0dNbNpAPmfx9IrSUSy0GjYtwLn/qz2Aq+mU46IZKWeobeNwHzgcjMbAB4HVgGbzOxHwGFgSZZFSrLy+9uLvfrq2P07PGPGjMT+8o/qET+6F6sZdndfWqXr1pRrEZEM6XJZkSAUdpEgFHaRIBR2kSAUdpEgdAVdB1i2bFli/8aNGwvLla5SGx4ervra8eOz/Xtevu/ydpb7b/Ht2Rc8HdlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgtA4ewucPn06sf/o0aOJ/eVPeylvJ41lZ/mkmEr7Lm9nuf81a9Yk9i9atKiwPGfOHN59992SdjQ6sosEobCLBKGwiwShsIsEobCLBKGwiwShsIsEoXF2uWCdPJk8cfDtt99eWB4YGChpv/XWW4mvveaaa5orrgPpyC4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMbZW2DSpEmJ/VOnTm1RJelbvHhxYnv37t1VX1vrPv5mffLJJ1Xbn3/+eab77kT1zM++DlgIHHP32fl1TwA/Bo7nf+0xd/9DVkWKSPPqObKvB54FXipbv9rdf5F6RSKSiZrn7O6+CzjRglpEJEPj6pkvy8ymA9vLPsb/EPgC2AesdPfkC5VzNDmXSPYqPviv0S/ofgX8jFx4fwb8Evj7BrcV3gMPPJDYXzyx4+DgIBMmlP6zJf3BzvqBk8UPdezr66Onp6ekP8sv6GodqIr/28vft7fffjvxtdddd11TtXWihsLu7oV/JTP7NbA9tYpEJBMNjbOb2bSi5veB99IpR0SyUs/Q20ZgPnC5mQ0AjwPzzex6ch/jDwE/ybDGVHz22WeJ/f39/SXtnp4e+vr6Cu1bbrml6muvvPLKpmqr9XG0vL+8nTQ/e3d3d+K2V65cmdi/fPnyxP5yxe8ZwDvvvFP1d2+44YZRbbtc0n83nP8M++L3LeLc7jXD7u5LK6z+TQa1iEiGdLmsSBAKu0gQCrtIEAq7SBAKu0gQYW5xve+++xL733jjjZL24OAg9957b6F9xRVXVH3tgQMHEred9FqAp59+OrG/q6urpL1s2bKSdtIw0lNPPZW47WnTpiX211I8pDl58uTzhjhXrFhR9bXNXt2XNFV1pe0Xt7O+srAT6cguEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEkRdj6VKUdvuK1y4cGFi/+uvv17SrvREmGpmzZqV2P/aa68l9l9yySV17Qfgsssu49NPP63795u1bdu2xP7nnnuusLx3715uvPHGkv5aT4Rphp5UU1XFiwh0ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJIsw4e60pehcsWFDS3rNnDzfffHOhvX///kzqGq1OmxGmeN9DQ0Pn3Xuf5f5r/b9bPOa/e/du5s6dW2jv2LEj8bWjufahA2mcXSQyhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSSIMM+NrzVuWume9OJ1+/btS72mRo1myuZaz1ZvVvm+y9tZ7r943LySN998s6S9c+fOwvKkSZMyqamT1TM/+9XAS8BUYBh40d3XmNkU4BVgOrk52u9x95PZlSoizajnz+4gsNLdvwPMBVaY2bXAo0C/u88C+vNtEelQNcPu7h+7+4H88ingA+AqYBGwIf9rG4DFWRUpIs0b1bXxZjYd2AXMBg67++SivpPufmmNTbTt2niRQCpeG1/3F3Rm9k2gD3jY3b8ws7QK6wjlkyW+/PLLJes2btzY6pIqqnSzSad8QTcyMnLejS+d8gXdpEmTOH36dEk7mrr+JcxsIrmg/9bdN+dXHzWzafn+acCxbEoUkTTU/BhvZuPInZOfcPeHi9b/E/Cpu68ys0eBKe7+jzX217Ef4w8ePFjSnjlzZsm67u7uVpdUkW5x/X9btmxJ7L/zzjsz23eHa/hj/DzgAeCPZvYf+XWPAauATWb2I+AwsCSNKkUkGzXD7u7/TpW/FMCt6ZYjIlnR5bIiQSjsIkEo7CJBKOwiQSjsIkGEeZR0LWfOnClpX3TRRSXr3L3qa/v7+xO3/cwzzyT2Hz58uI4Kc8bSOPu8efMSt/3ss88m9l/g0ypnSY+SFolMYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlC4+wtUGu66Frj9MXuuusuNm/eXLJuyZLqdxdnPc6+adOmwnKl2pLcemvyTZMX+LTJ7aRxdpHIFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgNM4uMvZonF0kMoVdJAiFXSQIhV0kCIVdJAiFXSQIhV0kiJqzuJrZ1cBLwFRgGHjR3deY2RPAj4Hj+V99zN3/kFWhItKcmhfVmNk0YJq7HzCzi4H9wGLgHuBLd//FKPani2pEslfxopp65mf/GPg4v3zKzD4Arkq3NhHJ2qgulzWz6cAuYDbwD8APgS+AfcBKdz9ZYxM6sotkr7nLZc3sm0Af8LC7fwH8CvgL4HpyR/5fplCkiGSkriO7mU0EtgM73P2fK/RPB7a7++wam9KRXSR7jR3ZzWwc8Bvgg+Kg57+4O+f7wHvNVigi2ann2/i/Bv4N+CO5oTeAx4Cl5D7CjwCHgJ/kv8xLoiO7SPYqHtl1P7vI2KP72UUiU9hFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgqj5wMmUVbz1TkSypyO7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBCtHmcHwMxuA9YAXcBad1/VjjoqMbNDwClgCBh09++2sZZ1wELg2LnZdsxsCvAKMJ3c8/rvqWOOvVbV9gQdMI13wjTjbX3v2j39ecuP7GbWBTwH/B1wLbDUzK5tdR01fM/dr29n0PPWA7eVrXsU6Hf3WUB/vt0O6zm/NoDV+ffu+nYEPW+Q3ESj3wHmAivy/4+1+72rVhe04H1rx8f4m4A/uftBdz8D/B5Y1IY6Op677wJOlK1eBGzIL28AFre0qLwqtXUEd//Y3Q/kl08B56YZb+t7l1BXS7Qj7FcBfy5qD9BZ872PAG+Y2X4zW97uYiq44tw0W/mf32pzPeV+ambvmtk6M7u03cXkJx39K2APHfTeldUFLXjf2hH2StfHd9K0UPPc/QZypxkrzOxv2l3QBaSjpvGuMM14R2jX9OftCPsAcHVR+9vAkTbUUZG7H8n/PAZsIXfa0UmOnptBN//zWJvrKXD3o+4+5O7DwK9p43uXn2a8D/itu2/Or277e1eprla9b+0I+15glpnNMLOLgB8AW9tQx3nM7BtmdvG5ZWABnTcV9VagN7/cC7zaxlpKdMo03tWmGafN7127pz9v9SyuAJjZ7cC/kBt6W+fuP295ERWY2UxyR3PIDUv+rp21mdlGYD5wOXAUeBz4V2ATcA1wGFji7i3/oqxKbfMZ/TTeWdRWbZrxPbTxvUt5+vNRa0vYRaT1dAWdSBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBD/B2Sg0VkHkTzSAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fda34349128>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvMhh3JoW8RV",
        "colab_type": "text"
      },
      "source": [
        "## Define the model.\n",
        "Let's start with a very simple linear classifier. All our models will have this basic interface -- they will take an image and return logits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3t3QXgSW8RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_model(img):\n",
        "    #TODO\n",
        "    X = tf.reshape(tensor = img, shape = [-1, HEIGHT * WIDTH])  #Flatten\n",
        "    W = tf.get_variable(name = \"W\", shape = [HEIGHT * WIDTH, NCLASSES], initializer = tf.truncated_normal_initializer(stddev = 0.1, seed = 1))  #Weight\n",
        "    b = tf.get_variable(name = \"b\", shape = [NCLASSES], initializer = tf.zeros_initializer)  #Bias\n",
        "    ylogits = tf.matmul(a = X, b = W) + b   # y = ax+b -> XW + b\n",
        "    return ylogits, NCLASSES"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lf2t_GKW8Ra",
        "colab_type": "text"
      },
      "source": [
        "## Write Input Functions\n",
        "\n",
        "As usual, we need to specify input functions for training, evaluation, and predicition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YspmksX7W8Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    x = {\"image\": mnist.train.images},\n",
        "    y = mnist.train.labels,\n",
        "    batch_size = 100,\n",
        "    num_epochs = None,\n",
        "    shuffle = True,\n",
        "    queue_capacity = 5000\n",
        ")\n",
        "\n",
        "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
        "    #TODO\n",
        "    x = {\"image\": mnist.train.images},\n",
        "    y = mnist.train.labels,\n",
        "    batch_size = 100,\n",
        "    num_epochs = 1,\n",
        "    shuffle = False,\n",
        "    queue_capacity = 5000\n",
        ")\n",
        "\n",
        "def serving_input_fn():\n",
        "    inputs = {\"image\": tf.placeholder(dtype = tf.float32, shape = [None, HEIGHT, WIDTH])}\n",
        "    features = inputs # as-is\n",
        "    return tf.estimator.export.ServingInputReceiver(features = features, receiver_tensors = inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmT3J2uGW8Rc",
        "colab_type": "text"
      },
      "source": [
        "## Write Custom Estimator\n",
        "I could have simply used a canned LinearClassifier, but later on, I will want to use different models, and so let's write a custom estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z04EjJVkW8Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_classifier(features, labels, mode, params):\n",
        "    ylogits, nclasses = linear_model(features[\"image\"])\n",
        "    probabilities = tf.nn.softmax(logits = ylogits)\n",
        "    class_ids = tf.cast(x = tf.argmax(input = probabilities, axis = 1), dtype = tf.uint8)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN or mode == tf.estimator.ModeKeys.EVAL:\n",
        "        loss = tf.reduce_mean(input_tensor = tf.nn.softmax_cross_entropy_with_logits_v2(logits = ylogits, labels = labels))\n",
        "        \n",
        "        if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "            train_op = tf.contrib.layers.optimize_loss(\n",
        "                loss = loss, \n",
        "                global_step = tf.train.get_global_step(),\n",
        "                learning_rate = params[\"learning_rate\"], \n",
        "                optimizer = \"Adam\")\n",
        "            eval_metric_ops = None\n",
        "        else:\n",
        "            train_op = None\n",
        "            eval_metric_ops =  {\"accuracy\": tf.metrics.accuracy(labels = tf.argmax(input = labels, axis = 1), predictions = class_ids)}\n",
        "    else:\n",
        "        loss = None\n",
        "        train_op = None\n",
        "        eval_metric_ops = None\n",
        " \n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode = mode,\n",
        "        predictions = {\"probabilities\": probabilities, \"class_ids\": class_ids},\n",
        "        loss = loss,\n",
        "        train_op = train_op,\n",
        "        eval_metric_ops = eval_metric_ops,\n",
        "        export_outputs = {\"predictions\": tf.estimator.export.PredictOutput({\"probabilities\": probabilities, \"class_ids\": class_ids})}\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZQKIa5EW8Rg",
        "colab_type": "text"
      },
      "source": [
        " tf.estimator.train_and_evaluate does distributed training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RuOZmBOW8Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_evaluate(output_dir, hparams):\n",
        "    estimator = tf.estimator.Estimator(\n",
        "        model_fn = image_classifier,\n",
        "        model_dir = output_dir,\n",
        "        params = hparams)\n",
        "\n",
        "    train_spec = tf.estimator.TrainSpec(\n",
        "        input_fn = train_input_fn,\n",
        "        max_steps = hparams[\"train_steps\"])\n",
        "\n",
        "    exporter = tf.estimator.LatestExporter(name = \"exporter\", serving_input_receiver_fn = serving_input_fn)\n",
        "\n",
        "    eval_spec = tf.estimator.EvalSpec(\n",
        "        input_fn = eval_input_fn,\n",
        "        steps = None,\n",
        "        exporters = exporter)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(estimator = estimator, train_spec = train_spec, eval_spec = eval_spec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHVHRfeuW8Rl",
        "colab_type": "text"
      },
      "source": [
        "This is the main() function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q70Y2HNDW8Rm",
        "colab_type": "code",
        "colab": {},
        "outputId": "f690037b-e37f-4c97-c440-3860a5604b56"
      },
      "source": [
        "OUTDIR = \"mnist/learned\"\n",
        "shutil.rmtree(path = OUTDIR, ignore_errors = True) # start fresh each time\n",
        "\n",
        "hparams = {\"train_steps\": 1000, \"learning_rate\": 0.01}\n",
        "train_and_evaluate(OUTDIR, hparams)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_service': None, '_log_step_count_steps': 100, '_master': '', '_task_type': 'worker', '_session_config': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_train_distribute': None, '_model_dir': 'mnist/learned', '_keep_checkpoint_max': 5, '_is_chief': True, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fda34344ac8>, '_num_worker_replicas': 1, '_tf_random_seed': None, '_num_ps_replicas': 0, '_evaluation_master': '', '_task_id': 0, '_save_checkpoints_steps': None}\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:step = 1, loss = 2.3983953\n",
            "INFO:tensorflow:global_step/sec: 226.23\n",
            "INFO:tensorflow:step = 101, loss = 0.40336028 (0.448 sec)\n",
            "INFO:tensorflow:global_step/sec: 264.615\n",
            "INFO:tensorflow:step = 201, loss = 0.35722628 (0.377 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.57\n",
            "INFO:tensorflow:step = 301, loss = 0.33209 (0.397 sec)\n",
            "INFO:tensorflow:global_step/sec: 249.085\n",
            "INFO:tensorflow:step = 401, loss = 0.37737605 (0.401 sec)\n",
            "INFO:tensorflow:global_step/sec: 247.712\n",
            "INFO:tensorflow:step = 501, loss = 0.2998476 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 242.577\n",
            "INFO:tensorflow:step = 601, loss = 0.2738968 (0.410 sec)\n",
            "INFO:tensorflow:global_step/sec: 277.809\n",
            "INFO:tensorflow:step = 701, loss = 0.26072544 (0.356 sec)\n",
            "INFO:tensorflow:global_step/sec: 238.506\n",
            "INFO:tensorflow:step = 801, loss = 0.40736407 (0.421 sec)\n",
            "INFO:tensorflow:global_step/sec: 256.899\n",
            "INFO:tensorflow:step = 901, loss = 0.36404133 (0.388 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into mnist/learned/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.2553848.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-05-04-08:39:04\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2019-05-04-08:39:05\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9241091, global_step = 1000, loss = 0.2715117\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
            "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predictions', 'serving_default']\n",
            "INFO:tensorflow:Restoring parameters from mnist/learned/model.ckpt-1000\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: b\"mnist/learned/export/exporter/temp-b'1556959145'/saved_model.pb\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qI3Jg-6W8Ro",
        "colab_type": "text"
      },
      "source": [
        "What accuracy did you achieve?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeOm9m5HW8Rp",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "# Copyright 2017 Google Inc. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#      http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "</pre>"
      ]
    }
  ]
}